#######################################################################
# Test for copying block of size 4;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $4, %rdx		# src and dst have 4 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
    # corrupt all the unused registers to prevent assumptions
    irmovq $0x5710331, %rax
    irmovq $0x5710331, %rbx
    irmovq $0x5710331, %rcx
    irmovq $0x5710331, %rbp
    irmovq $0x5710331, %r8
    irmovq $0x5710331, %r9
    irmovq $0x5710331, %r10
    irmovq $0x5710331, %r11
    irmovq $0x5710331, %r12
    irmovq $0x5710331, %r13
    irmovq $0x5710331, %r14
	call absrev		 
	halt			# should halt with abs sum in %rax
StartFun:
absrev:
    xorq %rax, %rax	# sum = 0;
    xorq %rcx, %rcx # *dst_rev = 0
    addq %rdx, %rcx 
    addq %rcx, %rcx
    addq %rcx, %rcx
    addq %rcx, %rcx
    addq %rsi, %rcx # *dst_rev = dst + len
    irmovq $8, %r12
    subq %r12, %rcx  # *dst_rev = dst + len - 1
	subq  %r12, %rdx # if len < 6 go to M
	jl     M     

K:
	mrmovq (%rdi), %r8     	# src[i] to %r8
	mrmovq 8(%rdi), %r9    	# src[i+1] to %r9
	rmmovq %r8, (%rcx)     	# src[i] to dst[len - 1]
    andq   %r8, %r8       	# src[i] <= 0?
    jle K1
    addq %r8, %rax #sum +=src[i]
    jmp K2
K1:
    subq %r8, %rax 
K2:
    rmmovq %r9, -8(%rcx) # src [i+1] to dst[len-2]
    andq   %r9, %r9      # src [i+1] <= 0?
    jle K4
    addq %r9, %rax #sum +=src[i+1]
    jmp K5
K4:
    subq %r9, %rax
K5:
    mrmovq 16(%rdi), %r8    # src[i+2] to %r8
	mrmovq 24(%rdi), %r9    	# src[i+3] to %r9
	rmmovq %r8, -16(%rcx)     	# src[i+2] to dst[len -3]
    andq   %r8, %r8       	# src[i+2] <= 0?
    jle K6
    addq %r8, %rax #sum +=src[i+2]
    jmp K7
K6:
    subq %r8, %rax
K7:
    rmmovq %r9, -24(%rcx) # src [i+3] to dst[len-4]
    andq   %r9, %r9      # src [i+3] <= 0?
    jle K8
    addq %r9, %rax #sum +=src[i+3]
    jmp K9
K8:
    subq %r9, %rax
K9:
    mrmovq 32(%rdi), %r8    # src[i+4] to %r8
	mrmovq 40(%rdi), %r9   	# src[i+5] to %r9    
	rmmovq %r8, -32(%rcx)   # src[i+4] to dst[len-5]
    andq   %r8, %r8       	# src[i+4] <= 0?
    jle K10
    addq %r8, %rax #sum +=src[i+4]
    jmp K11
K10:
    subq %r8, %rax 
K11:
    rmmovq %r9, -40(%rcx)   # src[i+5] to dst[len-6]
    andq   %r9, %r9       	# src[i+4] <= 0?
    jle K12
    addq %r9, %rax #sum +=src[i+5]
    jmp K13
K12:
    subq %r9, %rax     
K13:
    mrmovq 48(%rdi), %r8    # src[i+6] to %r8
    mrmovq 56(%rdi), %r9   	# src[i+7] to %r9 
	rmmovq %r8, -48(%rcx)   # src[i+6] to dst[len-7]
    andq   %r8, %r8       	# src[i+6] <= 0?
    jle K14
    addq %r8, %rax #sum +=src[i+6]
    jmp K15
K14:
    subq %r8, %rax 
K15:
    rmmovq %r9, -56(%rcx)   # src[i+7] to dst[len-8]
    andq   %r9, %r9       	# src[i+7] <= 0?
    jle K16
    addq %r9, %rax #sum +=src[i+7]
    jmp K17
K16:
    subq %r9, %rax     
K17:
#    irmovq $64, %r12 
#    addq  %r12, %rdi  # src = src+6
#    subq %r12, %rcx # dst = dst-6
	leaq 64(%rdi), %rdi
	leaq -64(%rcx),%rcx
	irmovq $8, %r12
	subq  %r12, %rdx # if len >= 6 go to K
	jge K     



M:
	addq  %r12, %rdx #original len val
	irmovq $1, %r12 
	subq  %r12, %rdx #len--
	jge M0 
	ret #if len<= return
M0:
	mrmovq (%rdi), %r8     	# src[i] to %r8
	mrmovq 8(%rdi), %r9    	# src[i+1] to %r9
	rmmovq %r8, (%rcx)     	# src[i] to dst[len - 1]
    andq   %r8, %r8       	# src[i] <= 0?
    jle M1
    addq %r8, %rax #sum +=src[i]
    jmp M2
M1:
    subq %r8, %rax 
M2:
    subq  %r12, %rdx #len--
	jge M3 
	ret #if len<= return   
M3:
    rmmovq %r9, -8(%rcx) # src [i+1] to dst[len-2]
    andq   %r9, %r9      # src [i+1] <= 0?
    jle M4
    addq %r9, %rax #sum +=src[i+1]
    jmp M5
M4:
    subq %r9, %rax
M5:
    subq  %r12, %rdx #len--
	jge M6 
	ret #if len<= return   
M6:
    mrmovq 16(%rdi), %r8    # src[i+2] to %r8
	mrmovq 24(%rdi), %r9    	# src[i+3] to %r9
	rmmovq %r8, -16(%rcx)     	# src[i+2] to dst[len -3]
    andq   %r8, %r8       	# src[i+2] <= 0?
    jle M7
    addq %r8, %rax #sum +=src[i+2]
    jmp M8
M7:
    subq %r8, %rax
M8:
    subq  %r12, %rdx #len--
	jge M9 
	ret #if len<= return   
M9:
    rmmovq %r9, -24(%rcx) # src [i+3] to dst[len-4]
    andq   %r9, %r9      # src [i+3] <= 0?
    jle M10
    addq %r9, %rax #sum +=src[i+3]
    jmp M11
M10:
    subq %r9, %rax
M11:
    subq  %r12, %rdx #len--
	jge M12 
	ret #if len<= return 
M12:
    mrmovq 32(%rdi), %r8    # src[i+4] to %r8
    mrmovq 40(%rdi), %r9    # src[i+5] to %r9
	rmmovq %r8, -32(%rcx)   # src[i+4] to dst[len-5]
    andq   %r8, %r8       	# src[i+4] <= 0?
    jle M13
    addq %r8, %rax #sum +=src[i+4]
    jmp M14
M13:
    subq %r8, %rax 
M14:
    subq  %r12, %rdx #len--
	jge M15 
	ret #if len<= return   
M15:
    rmmovq %r9, -40(%rcx) # src [i+5] to dst[len-6]
    andq   %r9, %r9      # src [i+5] <= 0?
    jle M16
    addq %r9, %rax #sum +=src[i+5]
    jmp M17
M16:
    subq %r9, %rax
M17:
    subq  %r12, %rdx #len--
	jge M18
	ret #if len<= return   
M18:
    mrmovq 48(%rdi), %r8    # src[i+6] to %r8
	rmmovq %r8, -48(%rcx)   # src[i+6] to dst[len-7]
    andq   %r8, %r8       	# src[i+6] <= 0?
    jle M19
    addq %r8, %rax #sum +=src[i+6]
    jmp M20
M19:
    subq %r8, %rax 
M20:
    ret

EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad -2
	.quad 3
	.quad 4
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
